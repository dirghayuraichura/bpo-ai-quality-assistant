# Contact Center AI Analysis Backend

A Node.js backend API for analyzing contact center conversations using AI-powered speech-to-text and LLM analysis to generate coaching plans for agents.

## Features

- ğŸ¤ **Audio File Upload**: Support for WAV and MP3 files via Multer
- ğŸ¯ **Speech-to-Text**: OpenAI Whisper API integration (production ready)
- ğŸ§  **LLM Analysis**: OpenAI GPT API for conversation analysis (production ready)
- ğŸ“‹ **Coaching Plans**: Automated generation of personalized coaching recommendations
- ğŸ“Š **Analytics**: Performance metrics and reporting
- ğŸ”’ **Security**: Helmet, CORS, input validation
- ğŸ“ **Logging**: Request logging with Morgan
- ğŸ—„ï¸ **Database**: MongoDB with Mongoose ODM

## Tech Stack

- **Framework**: Express.js
- **Database**: MongoDB with Mongoose
- **File Upload**: Multer
- **Validation**: Joi
- **Security**: Helmet, CORS
- **Environment**: dotenv
- **Development**: nodemon
- **Module System**: ES6 modules

## Project Structure

```
backend/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.js          # Environment configuration
â”‚   â””â”€â”€ database.js        # MongoDB connection
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ AudioFile.js       # Audio file metadata
â”‚   â”œâ”€â”€ Transcript.js      # Transcription results
â”‚   â”œâ”€â”€ Analysis.js        # LLM analysis results
â”‚   â”œâ”€â”€ CoachingPlan.js    # Coaching recommendations
â”‚   â””â”€â”€ index.js           # Model exports
â”œâ”€â”€ controllers/
â”‚   â”œâ”€â”€ uploadController.js    # File upload operations
â”‚   â”œâ”€â”€ transcriptController.js # STT operations
â”‚   â”œâ”€â”€ analysisController.js   # LLM analysis operations
â”‚   â””â”€â”€ coachingController.js   # Coaching plan operations
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ uploadRoutes.js    # Upload endpoints
â”‚   â”œâ”€â”€ transcriptRoutes.js # Transcript endpoints
â”‚   â”œâ”€â”€ analysisRoutes.js   # Analysis endpoints
â”‚   â”œâ”€â”€ coachingRoutes.js   # Coaching endpoints
â”‚   â””â”€â”€ index.js           # Route organization
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ sttService.js      # Mock STT service
â”‚   â”œâ”€â”€ llmService.js      # Mock LLM service
â”‚   â””â”€â”€ uploadService.js   # File handling service
â”œâ”€â”€ uploads/               # File upload directory
â”œâ”€â”€ package.json
â”œâ”€â”€ .env                   # Environment variables
â””â”€â”€ index.js              # Main server file
```

## Installation

1. **Clone the repository**
   ```bash
   cd backend
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Set up environment variables**
   ```bash
   # Copy the example environment file
   cp .env.example .env
   
   # Edit .env with your configuration
   ```

4. **Start MongoDB**
   ```bash
   # Using MongoDB locally
   mongod
   
   # Or using MongoDB Atlas (cloud service)
   # Update MONGODB_URI in .env with your Atlas connection string
   ```

5. **Run the application**
   ```bash
   # Development mode with nodemon
   npm run dev
   
   # Production mode
   npm start
   ```

## Environment Variables

```env
# Server Configuration
PORT=3001
NODE_ENV=development

# Database Configuration
MONGODB_URI=mongodb://localhost:27017/contact_center_ai

# File Upload Configuration
MAX_FILE_SIZE=50MB
UPLOAD_PATH=./uploads

# API Keys (OpenAI for both STT and LLM)
OPENAI_API_KEY=your_openai_api_key_here

# CORS Configuration
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:3001
```

## API Endpoints

### Health & Status

- `GET /` - API information
- `GET /api/health` - Health check
- `GET /api/status` - Service status

### File Upload

- `POST /api/upload` - Upload audio file
- `GET /api/upload` - List uploaded files (with pagination)
- `GET /api/upload/:id` - Get file information
- `PATCH /api/upload/:id/status` - Update file status
- `DELETE /api/upload/:id` - Delete file
- `GET /api/upload/stats/overview` - Upload statistics

### Transcription

- `POST /api/transcript/:audioFileId` - Transcribe audio file
- `GET /api/transcript` - List transcripts (with pagination)
- `GET /api/transcript/:id` - Get transcript by ID
- `GET /api/transcript/audio/:audioFileId` - Get transcript by audio file
- `PUT /api/transcript/:id` - Update transcript
- `DELETE /api/transcript/:id` - Delete transcript
- `GET /api/transcript/stats/overview` - Transcript statistics

### Analysis

- `POST /api/analysis/:transcriptId` - Analyze transcript
- `GET /api/analysis` - List analyses (with pagination)
- `GET /api/analysis/:id` - Get analysis by ID
- `GET /api/analysis/transcript/:transcriptId` - Get analysis by transcript
- `DELETE /api/analysis/:id` - Delete analysis
- `GET /api/analysis/stats/overview` - Analysis statistics
- `GET /api/analysis/stats/sentiment-summary` - Sentiment analysis summary

### Coaching

- `POST /api/coaching/:analysisId` - Generate coaching plan
- `GET /api/coaching` - List coaching plans (with pagination)
- `GET /api/coaching/:id` - Get coaching plan by ID
- `GET /api/coaching/analysis/:analysisId` - Get coaching plan by analysis
- `GET /api/coaching/agent/:agentId` - Get coaching plans by agent
- `PUT /api/coaching/:id` - Update coaching plan
- `DELETE /api/coaching/:id` - Delete coaching plan
- `GET /api/coaching/stats/overview` - Coaching statistics
- `GET /api/coaching/stats/agent-summary/:agentId` - Agent performance summary

## Usage Examples

### 1. Upload Audio File

```bash
curl -X POST http://localhost:3001/api/upload \
  -F "audioFile=@/path/to/audio.wav"
```

### 2. Transcribe Audio

```bash
curl -X POST http://localhost:3001/api/transcript/AUDIO_FILE_ID \
  -H "Content-Type: application/json" \
  -d '{"language": "en"}'
```

### 3. Analyze Transcript

```bash
curl -X POST http://localhost:3001/api/analysis/TRANSCRIPT_ID
```

### 4. Generate Coaching Plan

```bash
curl -X POST http://localhost:3001/api/coaching/ANALYSIS_ID \
  -H "Content-Type: application/json" \
  -d '{"agentId": "agent_001"}'
```

## Complete Workflow Example

```bash
# 1. Upload audio file
UPLOAD_RESPONSE=$(curl -s -X POST http://localhost:3001/api/upload \
  -F "audioFile=@sample_call.wav")
AUDIO_FILE_ID=$(echo $UPLOAD_RESPONSE | jq -r '.data.id')

# 2. Transcribe the audio
TRANSCRIPT_RESPONSE=$(curl -s -X POST http://localhost:3001/api/transcript/$AUDIO_FILE_ID \
  -H "Content-Type: application/json" \
  -d '{"language": "en"}')
TRANSCRIPT_ID=$(echo $TRANSCRIPT_RESPONSE | jq -r '.data.transcriptId')

# 3. Analyze the transcript
ANALYSIS_RESPONSE=$(curl -s -X POST http://localhost:3001/api/analysis/$TRANSCRIPT_ID)
ANALYSIS_ID=$(echo $ANALYSIS_RESPONSE | jq -r '.data.analysisId')

# 4. Generate coaching plan
COACHING_RESPONSE=$(curl -s -X POST http://localhost:3001/api/coaching/$ANALYSIS_ID \
  -H "Content-Type: application/json" \
  -d '{"agentId": "agent_001"}')

echo "Coaching Plan Generated: $(echo $COACHING_RESPONSE | jq -r '.data.coachingPlanId')"
```

## Data Models

### AudioFile
- Stores uploaded audio file metadata
- Tracks processing status
- Links to transcripts and analyses

### Transcript
- Contains speech-to-text results
- Includes confidence scores and segments
- Supports multiple languages

### Analysis
- LLM analysis results including:
  - Sentiment analysis
  - Emotion detection
  - Key topics extraction
  - Communication metrics
  - Customer satisfaction scores
  - Compliance assessment

### CoachingPlan
- Personalized coaching recommendations
- Performance scoring and levels
- Strengths and improvement areas
- Action items and training recommendations
- Follow-up milestones

## Error Handling

The API provides comprehensive error handling with:
- Input validation using Joi
- File upload error handling
- MongoDB error translation
- Request tracking with unique IDs
- Detailed error responses in development
- Sanitized errors in production

## Security Features

- **Helmet**: Security headers
- **CORS**: Cross-origin resource sharing
- **File Validation**: Type and size restrictions
- **Input Validation**: Joi schema validation
- **Error Sanitization**: Safe error responses



### Environment Setup
1. Set `NODE_ENV=production`
2. Use production MongoDB URI
3. Configure real STT and LLM API keys
4. Set up proper CORS origins
5. Configure file upload limits

### Production Deployment

#### Option 1: Traditional Server Deployment
1. Set up a Node.js server (Ubuntu/CentOS/Windows Server)
2. Install MongoDB or use MongoDB Atlas
3. Clone the repository and install dependencies
4. Configure environment variables
5. Use PM2 or similar process manager:
   ```bash
   npm install -g pm2
   pm2 start index.js --name "contact-center-ai"
   pm2 startup
   pm2 save
   ```

#### Option 2: Cloud Platform Deployment
- **Heroku**: Deploy directly from Git repository
- **Railway**: Simple Node.js deployment
- **Render**: Free tier available for development
- **Vercel**: Serverless deployment option
- **AWS EC2**: Full control over server environment

### Integration with Real Services

To integrate with real AI services, update:

1. **STT Service**: Currently set up for OpenAI Whisper API
   - Add actual OpenAI API calls to replace mock responses
   - Implement proper error handling for API failures
   - Add retry logic and rate limiting

2. **LLM Service**: Currently set up for OpenAI GPT API
   - Add actual OpenAI API calls for analysis and coaching generation
   - Implement proper prompt engineering for conversation analysis
   - Add error handling and fallback mechanisms
